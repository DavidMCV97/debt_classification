{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3378944d-a305-4fa2-9adf-597d226f0f31",
   "metadata": {},
   "source": [
    "# General debt projection v.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b289060d-aa53-43f0-ac56-9572b0ec1b88",
   "metadata": {},
   "source": [
    "The objetive of debt projection, as its name says, is to make a projection or aproximation of the payment needed to liquidate the debt during the current month. The projection works based on the behavior of similar debts during recent months. Particularly, the payment projection will be based on the behavior of debts of the same bank and with the same deliquency time during the last twelve months. The projection will be presented as a discount over the actual balance of the debt. As we don't know the actual balance of the debt, we will need to make an aproximation of that too.\n",
    "\n",
    "We have two metods for discount projection. Noah method uses the last discount the debt got and projects the new discount as the next discount on the list. The list is created based on the behavior of the debts. Percentil method uses the 15% percentil discount curve for each deliquency time and projects the new discount as the corresponding discount depending on the created curve. Noah method will be the main method, while percentil method will only be used on debts with no history of discounts.\n",
    "\n",
    "The process of projection will follow the next steps:\n",
    "\n",
    "1. Establishing parameters for the algorithm.\n",
    "2. Import and clean data.\n",
    "3. Actual balance aproximation.\n",
    "4. Logarithmic discount curve adjustment.\n",
    "5. Use of the curves for discount projection\n",
    "    1. Noah Method.\n",
    "    2. Percentil Metod.\n",
    "6. Saving results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970abd58-0dd8-4552-bc73-2401e0444c05",
   "metadata": {},
   "source": [
    "## Parameters of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49238c3-3dfb-464c-ada1-4d02048615cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd # for dataframes\n",
    "import numpy as np # for numerical processes\n",
    "import matplotlib.pyplot as plt # for graphs\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceaef9b4-b871-42a5-b825-9de3e03c78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "pd.set_option('display.max_columns', 100) # displays 100 columns on dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6368bd20-e872-477d-9ec2-317ab6646edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "activities_source = 'BBVA activities apr23-mar24.csv' # activities are the history of discounts\n",
    "bins_source = 'BBVA_bins.csv' # bins indicate the interest rate of each debt\n",
    "results_file_name = 'descuentos_proyectados_BBVA.csv'\n",
    "result_curve1_file_name = 'curva_descunto_BBVA.csv'\n",
    "bank_input = 'card' # card or loan (only for BBVA and Santander, for other banks write False)\n",
    "max_period = 18 #max period of interest grow\n",
    "max_discount = 0.85 # max discount for projections\n",
    "default_discount = 0.75 # default discount for bigger deliquencies than curve size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19250073-e3bd-49c7-b875-774fc5d41670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced parameters\n",
    "date_format = '%Y-%m-%d' # for formatting on date\n",
    "default_interest_rate = 0.04\n",
    "bigger_tolerance_rate = 3 # max times payment can be bigger than debt. bigger will be considered a mistake.\n",
    "max_discount_tolerance = 0.98 #max discount. bigger will be considered a mistake.\n",
    "curve_size = 20 # deliq months to consider in curves\n",
    "percentile_1 = 15 # smaller percentil for percentil method\n",
    "percentile_2 = 50 # bigger percentil for Noah metod\n",
    "today = np.datetime64('today') #analysis date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec1ef21-9621-4ea7-bd1e-f88c5c8ab1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent method parameters\n",
    "a0 = [0.4,10] # initial parameters\n",
    "a1 = a0 + np.random.rand(2)*[0.1,1] # initial parameters\n",
    "iterations = 100\n",
    "step = 0.01\n",
    "parameter_range = 4 # discrete steps to try for the beggining of the log function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde4a772-388a-4b15-af35-d60c8340f2d9",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244d19be-5744-4bf6-bbd2-15ec19eea45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "activities = pd.read_csv(activities_source)\n",
    "bins = pd.read_csv(bins_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0138b1c8-4c9e-4885-8cc9-9dc3349a08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean activities\n",
    "activities.inicio_programa = pd.to_datetime(activities.inicio_programa,format=date_format,errors='coerce') # errors in cast will be NaT\n",
    "activities.ultimo_pago = pd.to_datetime(activities.ultimo_pago,format=date_format,errors='coerce')\n",
    "activities.executed_date = pd.to_datetime(activities.executed_date,format=date_format,errors='coerce')\n",
    "activities[['bank_reference','debt_id','banco','num_tarjeta']] = activities[['bank_reference','debt_id','banco','num_tarjeta']].astype(str) #simultaneous cast\n",
    "activities.dropna(inplace=True) #drop rows with null or NaT values\n",
    "activities.reset_index(drop = True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb21bb4-b309-4258-bf8c-cd9626cf5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean Bins\n",
    "bins['Bin'] = bins['Bin'].astype(str).str.zfill(6) # zfill ensures data has 6 digits, fills with zeros.\n",
    "bins.drop_duplicates('Bin',inplace=True)\n",
    "bins.reset_index(drop = True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03cfd5d-96b2-42c8-97ad-86299fa8583f",
   "metadata": {},
   "source": [
    "## Balance Aproximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7199e5b-43ba-43f2-b64f-4c546c5265a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bank_input: # 'if' reads anything thats not 'False' or 0 as True\n",
    "    cards = activities.num_tarjeta.str.replace(r'\\D','',regex=True) # regex help us filter only numeric values\n",
    "    cards_len = cards.str.len()\n",
    "    activities['bank_type'] = np.where((cards_len >= 15)&(cards_len <= 17), 'card','loan') # cards have 16 digits\n",
    "    activities['Bin'] = cards.str[:6]\n",
    "    activities = activities[activities.bank_type == bank_input].reset_index(drop = True) # reset index help us keep an ordered dataframe\n",
    "else:\n",
    "    cards = activities.num_tarjeta.str.replace(r'\\D','',regex=True)\n",
    "    activities['Bin'] = cards.str[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08b4c511-8142-4b2b-b11d-73595d48be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.merge(activities, bins, on = 'Bin', how = 'left') # we merge to find interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cdcd1e2-6561-4839-ae5b-2fd674e869be",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.tasa = activities.tasa.fillna(default_interest_rate) # we fill with default interest rate bins not find\n",
    "#we use the date formula [(Y2-Y1)*12 + M2-M1] to calculate deliquencies\n",
    "activities['deliq_beginning_prog'] = (activities.inicio_programa.dt.year - activities.ultimo_pago.dt.year)*12 + activities.inicio_programa.dt.month - activities.ultimo_pago.dt.month\n",
    "activities.deliq_beginning_prog = np.where(activities.deliq_beginning_prog < 0, 0, activities.deliq_beginning_prog)\n",
    "activities['deliq_act'] = (activities.executed_date.dt.year - activities.ultimo_pago.dt.year)*12 + activities.executed_date.dt.month - activities.ultimo_pago.dt.month\n",
    "activities.drop(activities[activities.deliq_act <0].index,inplace=True) # we drop negative periods as there must be a payment after the discount\n",
    "#aux_balance help us to know the deliquency months passed from last record\n",
    "activities['aux_balance'] = np.where(activities.deliq_beginning_prog > max_period, 0,\n",
    "                                     np.where(activities.deliq_act > max_period, max_period - activities.deliq_beginning_prog,\n",
    "                                              activities.deliq_act - activities.deliq_beginning_prog))\n",
    "# we use the compound interest formula for balance\n",
    "activities['balance'] = activities.deuda_resuelve*(1 + activities.tasa)**(activities.aux_balance)\n",
    "activities['real_discount'] = 1-activities.pago_a_bancos/activities.balance\n",
    "# we filter activities to avoid incongruent payments\n",
    "activities.drop(activities[activities.deuda_resuelve*bigger_tolerance_rate < activities.pago_a_bancos].index, inplace = True)\n",
    "activities.drop(activities[activities.real_discount > max_discount_tolerance].index,inplace=True)\n",
    "activities.reset_index(drop = True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef03c2-4993-429f-89b7-12136f857319",
   "metadata": {},
   "source": [
    "## Curve Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5b364-5492-4d01-91a4-95e50175617a",
   "metadata": {},
   "source": [
    "### Gradent Descent Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225fba1-83bc-4416-9cb1-65ef7c5330ff",
   "metadata": {},
   "source": [
    "we'll use gradent descent metod to make an adjusted logarithmic curve that passess through the percentil points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a02e796-e0be-4c12-9809-e5580923baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent function\n",
    "def grad_desc(f,x0,x1,iterations,f_step):\n",
    "    # this is the gradent descent method for R^2 -> R functions that uses\n",
    "    # numerical aproximations of the derivate of the function.\n",
    "    xii = np.array(x0) # numpy arrays are better for math ops\n",
    "    xjj = np.array(x1) # j = i + 1\n",
    "    it = 0\n",
    "    while it < iterations and any(xii != xjj):\n",
    "        xji = np.array([xjj[0],xii[1]])\n",
    "        xij = np.array([xii[0],xjj[1]])\n",
    "        if xjj[0] == xii[0]:\n",
    "            df_dx = 0\n",
    "        else:\n",
    "            df_dx = (f(xji)-f(xii)) / (xjj[0]-xii[0])\n",
    "        if xjj[1] == xii[1]:\n",
    "            df_dy = 0\n",
    "        else:\n",
    "            df_dy = (f(xij)-f(xii)) / (xjj[1]-xii[1])\n",
    "        mov = np.array([df_dx,df_dy]) * (-f_step)\n",
    "        xii = xjj\n",
    "        xjj = xjj + mov\n",
    "        it = it + 1\n",
    "    return xjj,f(xjj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c2529-ea62-4744-a427-3693cd551a8f",
   "metadata": {},
   "source": [
    "### Curve Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c99890c-597a-4504-bb72-3a53846cb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = np.zeros(curve_size), np.zeros(curve_size) # initialize adjusted curves\n",
    "# basic percentile assignation to the curves\n",
    "for month in range(1,curve_size):\n",
    "    c1[month] = np.percentile(activities[activities.deliq_act == month].real_discount,percentile_1)\n",
    "    c2[month] = np.percentile(activities[activities.deliq_act == month].real_discount,percentile_2)\n",
    "#finding ideal parameters for the curves\n",
    "for curve in [c1,c2]:\n",
    "    for log_step in range(parameter_range):\n",
    "        # f is the logarithmic function we will use\n",
    "        def f(a,x):\n",
    "            if (x-log_step)*a[1] <= 0:\n",
    "                res = 0\n",
    "            else:\n",
    "                res = max(0,a[0]*np.log((x-log_step)*a[1]))\n",
    "            return res\n",
    "        # we use Mean Squared Error to evaluate error magnitude\n",
    "        def MSE(a): return mean_squared_error([f(a,x) for x in range(curve_size)],curve)\n",
    "        # we use grad desc to find optimal parameters\n",
    "        a_candidate,f_candidate = grad_desc(MSE,a0,a1,iterations,step)\n",
    "        # if we dont have an optimal value yet, use the first one\n",
    "        try:\n",
    "            if f_candidate < f_star:\n",
    "                a_star,f_star,log_step_star = a_candidate,f_candidate,log_step\n",
    "        except:\n",
    "            a_star,f_star,log_step_star = a_candidate,f_candidate,log_step\n",
    "    def f(a,x):\n",
    "        if (x-log_step_star)*a[1] <= 0:\n",
    "            res = 0\n",
    "        else:\n",
    "            res = max(0,a[0]*np.log((x-log_step_star)*a[1]))\n",
    "        return res\n",
    "    if all(curve == c1):\n",
    "        c1_adjusted = pd.DataFrame([f(a_star,x) for x in range(curve_size)],columns=['discount'])\n",
    "    else:\n",
    "        c2_adjusted = pd.DataFrame([f(a_star,x) for x in range(curve_size)],columns=['discount'])\n",
    "    del f_star # we delete it so its not saved for the next loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a647d1-34d2-4bfb-bd1a-2c02d4d907eb",
   "metadata": {},
   "source": [
    "## Discount Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc21a42-3d30-4893-ade8-de8ea2f0f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a dataframe 'debts' to filter info by debt\n",
    "debts = activities.sort_values(['debt_id','executed_date'],ascending=[True,False]).drop_duplicates([\"debt_id\"]).copy()\n",
    "debts = debts[['bank_reference','debt_id','ultimo_pago','deliq_beginning_prog','deuda_resuelve','tasa','real_discount','pago_a_bancos']].reset_index(drop = True)\n",
    "debts.rename(columns = {'real_discount':'last_discount','pago_a_bancos':'last_payment'},inplace=True)\n",
    "today = pd.to_datetime(today)\n",
    "debts['deliq_today'] = (today.year - debts.ultimo_pago.dt.year)*12 + today.month - debts.ultimo_pago.dt.month\n",
    "debts['aux_balance_today'] = np.where(debts.deliq_beginning_prog > max_period, 0,\n",
    "                                np.where(debts.deliq_today > max_period, max_period - debts.deliq_beginning_prog,\n",
    "                                         debts.deliq_today - debts.deliq_beginning_prog))\n",
    "debts[\"balance_today\"] = debts.deuda_resuelve*(1+debts.tasa)**(debts.aux_balance_today)\n",
    "#Now we apply Noah algorithm\n",
    "for indx in debts.index:\n",
    "    if debts.loc[indx,'last_discount'] > max_discount:\n",
    "        debts.loc[indx,'projected_discount'] = max_discount\n",
    "    else:\n",
    "        debts.loc[indx,'projected_discount'] = c2_adjusted.discount[c2_adjusted.discount > debts.loc[indx,'last_discount']].head(1).values\n",
    "debts['projected_payment'] = debts.balance_today * (1-debts.projected_discount)\n",
    "# as a final step, we will load only payments as good as the last one\n",
    "debts['load_adjustment'] = np.where(debts.projected_payment < debts.last_payment,\n",
    "                                   debts.projected_payment, debts.last_payment)                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708bb99-1e7a-49d6-884c-eddc3ab22ca3",
   "metadata": {},
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e46d11-871c-4555-970e-9e32d9a9f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "debts.to_csv(results_file_name)\n",
    "c1_adjusted.to_csv(result_curve1_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
